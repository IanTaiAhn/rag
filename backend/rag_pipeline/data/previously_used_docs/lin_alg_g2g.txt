Skip to content
geeksforgeeks
Search...
Interview PrepTutorialsTracks

Sign In
Number System and Arithmetic
Algebra
Set Theory
Probability
Statistics
Geometry
Calculus
Logarithms
Mensuration
Matrices

Sign In
▲
Linear Algebra
Last Updated : 02 Dec, 2025
Linear Algebra is the branch of mathematics that focuses on the study of vectors, vector spaces, matrices, and linear transformations. It deals with linear equations, linear functions, and their representations through matrices and determinants. It has a wide range of applications in Physics and Mathematics. It is the basic concept for machine learning and data science.

Some applications of Linear Algebra are:

_image_processing.webp_image_processing.webp

Linear Algebra Equations

The general linear equation is represented as u1x1 + u2x2 + ..... unxn = v

Where,

u’s – represents the coefficients
x’s – represents the unknowns
v – represents the constant
There is a collection of equations called a System of linear algebraic equations. It obeys the linear function such as -

 (x1,……..xn) → u1x1 + ………. + unxn

Types of Linear Algebra Study
Linear Algebra is divided into different branches based on the difficulty level of topics, which are,

Elementary Linear Algebra
Advanced Linear Algebra
Applied Linear Algebra
Foundations of Linear Algebra
Elementary linear algebra introduces the foundational concepts that form the building blocks of the subject. It covers basic operations on matrices, solving systems of equations, and understanding vectors.

elementary_linear_algebra


Scalars – Quantities with magnitude only (e.g., real numbers).
Vectors – Quantities with both direction and magnitude, elements of a vector space.
Vector Space – A collection of vectors that can be added and scaled by scalars.
Matrix – A rectangular array of numbers arranged in rows and columns.
Matrix Operations – Arithmetic operations like addition, multiplication, and transposition.
Abstract Linear Algebra
Advanced/Abstract linear algebra mostly covers all the advanced topics related to linear algebra, such as Linear function, Linear transformation, Eigenvectors, and Eigenvalues.

advanced_linear_algebra
Linear Transformations
A linear transformation is a special kind of function between vector spaces that preserves the operations of:

Vector addition
Scalar multiplication
In other words, if T is a linear transformation, then for any vectors u, v, and scalar c:

T(u + v) = T(u) + T(v)

T(cu) = cT(u)

Examples:

Rotation in 2D or 3D: Rotating a vector around the origin is a linear transformation.
Scaling: Stretching or shrinking a vector by multiplying it by a scalar.
Eigenvalues and Eigenvectors
Eigenvalues and eigenvectors are fundamental concepts in linear algebra. It offers deep insights into the properties of linear transformations. An eigenvector of a square matrix is a non-zero vector that, when the matrix multiplies it, results in a scalar multiple of itself. This scalar is known as the eigenvalue associated with the eigenvector. They are essential in various applications, including stability analysis, quantum mechanics, and the study of dynamical systems.

Consider a transformation that changes the direction or length of vectors, except for some special vectors that only get stretched or shrunk. These special vectors are eigenvectors, and the factor by which they are stretched or shrunk is the eigenvalue.

Example: For the matrix A = [2, 0, 0, 3], the vector v = 1, 0 is an eigenvector because Av = 2v, and 2 is the eigenvalue.

Singular Value Decomposition
Singular Value Decomposition (SVD) is a powerful mathematical technique used in signal processing, statistics, and machine learning. It decomposes a matrix into three other matrices, where one represents the rotation, another the scaling, and the third the final rotation. It's essential for identifying the intrinsic geometric structure of data.

Positive Definite Matrices
A positive definite matrix is a symmetric matrix where all its eigenvalues are positive. These matrices are significant in optimisation problems, as they ensure the existence of a unique minimum in quadratic forms.

Example: The matrix A = [2, 0, 0, 2] is positive definite because it always produces positive values for any non-zero vector.

Matrix Exponential
The matrix exponential is a function on square matrices analogous to the exponential function for real numbers. It is used in solving systems of linear differential equations, among other applications in physics and engineering.

Matrix exponentials stretch or compress spaces in ways that depend smoothly on time, much like how interest grows continuously in a bank account.

Example: The exponential of the matrix A = [0, −1, 1, 0] represents rotations, where the amount of rotation depends on the "time" parameter.

Linear Computations
Linear computations involve numerical methods for solving linear algebra problems, including systems of linear equations, eigenvalues, and eigenvectors calculations. These computations are essential in computer simulations, optimisations, and modelling.

These are techniques for crunching numbers in linear algebra problems, like finding the best-fit line through a set of points or solving systems of equations quickly and accurately.

Linear Independence
A set of vectors is linearly independent if no vector in the set is a linear combination of the others. The concept of linear independence is central to the study of vector spaces, as it helps define bases and dimension.

Vectors are linearly independent if none of them can be made by combining the others. It's like saying each vector brings something unique to the table that the others don't.

Example: 1,0 and 0,1 are linearly independent in 2D space because you can't create one of these vectors by scaling or adding the other.

Linear Subspace
A linear subspace (or simply subspace) is a subset of a vector space that is closed under vector addition and scalar multiplication. A subspace is a smaller space that lies within a larger vector space, following the same rules of vector addition and scalar multiplication.

Example: The set of all vectors of the form a, 0 in 2D space is a subspace, representing all points along the x-axis.

Practical Linear Algebra
In Applied Linear Algebra, the topics covered are generally the practical implications of Elementary and advanced linear Algebra topics such as the Complement of a matrix, matrix factorization and norm of vectors, etc.

applied_linear_algebra
Linear Programming
Linear programming is a method to achieve the best outcome in a mathematical model whose requirements are represented by linear relationships. It is widely used in business and economics to maximize profit or minimize cost while considering constraints.

This is a technique for optimizing (maximizing or minimizing) a linear objective function, subject to linear equality and inequality constraints. It's like planning the best outcome under given restrictions.

Example: Maximizing profit in a business while considering constraints like budget, material costs, and labor.

Linear Equation Systems
Systems of linear equations involve multiple linear equations that share the same set of variables. The solution to these systems is the set of values that satisfy all equations simultaneously, which can be found using various methods, including substitution, elimination, and matrix operations.

Example: Finding the intersection point of two lines represented by two equations.

Gaussian Elimination
Gaussian elimination is a systematic method for solving systems of linear equations. It involves applying a series of operations to transform the system's matrix into its row echelon form or reduced row echelon form, making it easier to solve for the variables. It is a step-by-step procedure to simplify a system of linear equations into a form that's easier to solve.

Example: Systematically eliminating variables in a system of equations until each equation has only one variable left to solve for.

Important Linear Algebra Topics
Below is the list of important topics in Linear Algebra.

Matrix Inverses and Determinants
Linear Transformations
Singular Value Decomposition
Orthogonal Matrices
Vector Projection
Solving systems of equations with matrices
Linear Algebra Applications
Linear algebra, with its concepts of vectors, matrices, and linear transformations, serves as a foundational tool in numerous fields, enabling the solving of complex problems across science, engineering, computer science, economics, and more.

Following are some specific applications of linear algebra in real-world.

1. Computer Graphics and Animation

Linear algebra is indispensable in computer graphics, gaming, and animation. It helps in transforming the shapes of objects and their positions in scenes through rotations, translations, scaling, and more. For instance, when animating a character, linear transformations are used to rotate limbs, scale objects, or shift positions within the virtual world.

2. Machine Learning and Data Science

In machine learning, linear algebra is at the heart of algorithms used for classifying information, making predictions, and understanding the structures within data. It's crucial for operations in high-dimensional data spaces, optimizing algorithms, and even in the training of neural networks where matrix and tensor operations define the efficiency and effectiveness of learning.

3. Quantum Mechanics

The state of quantum systems is described using vectors in a complex vector space. Linear algebra enables the manipulation and prediction of these states through operations such as unitary transformations (evolution of quantum states) and eigenvalue problems (energy levels of quantum systems).

4. Cryptography

Linear algebraic concepts are used in cryptography for encoding messages and ensuring secure communication. Public key cryptosystems, such as RSA, rely on operations that are easy to perform but extremely difficult to reverse without the key, many of which involve linear algebraic computations.

5. Network Analysis

Linear algebra is used to analyze and optimize networks, including internet traffic, social networks, and logistical networks. Google's PageRank algorithm, which ranks web pages based on their links to and from other sites, is a famous example that uses the eigenvectors of a large matrix representing the web.

6. Image and Signal Processing

Techniques from linear algebra are used to compress, enhance, and reconstruct images and signals. Singular value decomposition (SVD), for example, is a method to compress images by identifying and eliminating redundant information, significantly reducing the size of image files without substantially reducing quality.

Solved Examples on Linear Algebra
Example 1: Find the sum of the two vectors 
A
→
 
A
  = 2i + 3j + 5k and 
B
→
 
B
  = -i + 2j + k

Solution:

A
→
+
B
→
 
A
 + 
B
  = (2-1)i + (2 + 3)j + (5 + 1)k = i + 5j + 6k

Example 2: Find the dot product of 
P
→
 
P
  = -2i + j + 3k and 
Q
→
 
Q
​
  = i - 2j + k

Solution:

P
→
.
Q
→
 
P
 . 
Q
​
  = -2i(i - 2j + k) + j(i - 2j + k) + 3k(i - 2j + k)

= -2i -2j + 3k

Example 3: Find the solution of x + 2y = 3 and 3x + y = 5

Solution:

From x + 2y = 3 we get x = 3 - 2y

Putting this value of x in the second equation we get

3(3 - 2y) + y = 5
⇒ 9 - 6y + y = 5
⇒ 9 - 5y = 5
⇒ -5y = -4
⇒ y = 4/5

Putting this value of y in 1st equation we get

x + 2(4/5) = 3
⇒ x = 3 - 8/5
⇒ x = 7/5

Example 4: Matrix Multiplication, Find the product of the matrices:

A
=
(
1
2
3
4
)
,
    
B
=
(
5
6
7
8
)
A=( 
1
3
​
  
2
4
​
 ),    B=( 
5
7
​
  
6
8
​
 )

Solution:

A
B
=
(
1
∙
5
+
2
∙
7
1
∙
6
+
2
∙
8
3
∙
5
+
4
∙
7
3
∙
6
+
4
∙
8
)
=
(
5
+
14
6
+
16
15
+
28
18
+
32
)
=
(
19
22
43
50
)
AB=( 
1∙5+2∙7
3∙5+4∙7
​
  
1∙6+2∙8
3∙6+4∙8
​
 )=( 
5+14
15+28
​
  
6+16
18+32
​
 )=( 
19
43
​
  
22
50
​
 )

Example 5: Eigenvalues of a Matrix, Find the eigenvalues of the matrix:

A
=
(
3
8
0
6
)
A=( 
3
0
​
  
8
6
​
 )

Solution:

1. Write the characteristic equation:

A
 
−
 
λ
I
A − λI

2. Find the determinant (det) of characteristic equation:

∣
A
−
λ
I
∣
=
∣
3
−
λ
8
0
6
−
λ
∣
=
(
3
−
λ
)
(
6
−
λ
)
−
8
∙
0
=
(
3
−
λ
)
(
6
−
λ
)
∣A−λI∣= 
∣
∣
​
  
3−λ
0
​
  
8
6−λ
​
  
∣
∣
​
 =(3−λ)(6−λ)−8∙0=(3−λ)(6−λ) 

3. Equate the determinant with Zero "0":

(
3
−
λ
)
(
6
−
λ
)
=
0
⇒
λ
=
3
,
6
(3−λ)(6−λ)=0⇒λ=3,6 

Therefore, the eigenvalues are 3, 6.

Practice Problems - Linear Algebra
Question 1: Solve the system of equations:

x + y + z = 6
2x + 3y + 5z = 4
4x + 3y + z = 2
Question 2: Find the eigenvalues and eigenvectors of the matrix:

(
5
0
7
8
)
( 
5
7
​
  
0
8
​
 )

Question 3: Find the determinant of the matrix:

(
3
6
4
8
)
( 
3
4
​
  
6
8
​
 )

Question 4: Find the product of the matrices:

A
=
(
1
2
6
4
)
,
    
B
=
(
5
4
0
2
)
A=( 
1
6
​
  
2
4
​
 ),    B=( 
5
0
​
  
4
2
​
 )

Question 5: Solve a System of Linear Equations:

2x + 3y = 5
4x - y = 11
Question 6: Determine the characteristic equation of the matrix:

A
=
(
1
2
3
0
−
1
4
−
2
1
0
)
A= 
⎝
⎛
​
  
1
0
−2
​
  
2
−1
1
​
  
3
4
0
​
  
⎠
⎞
​
 

Question 7: Find the trace of the matrix:

A
=
(
1
2
3
0
−
1
4
−
2
1
0
)
A= 
⎝
⎛
​
  
1
0
−2
​
  
2
−1
1
​
  
3
4
0
​
  
⎠
⎞
​
 

Question 8: Compute the eigenvalues of the matrix:

A
=
(
1
2
3
0
−
1
4
−
2
1
0
)
A= 
⎝
⎛
​
  
1
0
−2
​
  
2
−1
1
​
  
3
4
0
​
  
⎠
⎞
​
 

Question 9: Compute the eigenvalues of the matrix:

A
=
(
1
2
6
4
)
A=( 
1
6
​
  
2
4
​
 )

Question 10: Verify if the vectors 
u
=
(
1
0
1
)
 
a
n
d
 
v
=
(
0
1
1
)
u= 
⎝
⎛
​
  
1
0
1
​
  
⎠
⎞
​
  and v= 
⎝
⎛
​
  
0
1
1
​
  
⎠
⎞
​
  are orthogonal.



Comment
A

abhishek1
 Follow

14
Article Tags :
Mathematics
Tutorials
linear algebra
Maths-Categories
Explore
Basic Arithmetic
Algebra
Geometry
Trigonometry & Vector Algebra
Calculus
Probability and Statistics
Practice
geeksforgeeks-footer-logo
Corporate & Communications Address:
A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)
Registered Address:
K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305
GFG App on Play Store
GFG App on App Store
Company
About Us
Legal
Privacy Policy
Contact Us
Advertise with us
GFG Corporate Solution
Campus Training Program
Explore
POTD
Job-A-Thon
Blogs
Nation Skill Up
Tutorials
Programming Languages
DSA
Web Technology
AI, ML & Data Science
DevOps
CS Core Subjects
Interview Preparation
Software and Tools
Courses
ML and Data Science
DSA and Placements
Web Development
Programming Languages
DevOps & Cloud
GATE
Trending Technologies
Videos
DSA
Python
Java
C++
Web Development
Data Science
CS Subjects
Preparation Corner
Interview Corner
Aptitude
Puzzles
GfG 160
System Design
@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved
Lightbox